 1019  cp pod1.yaml pod2.yaml
 1020  vi pod1.yaml
 1021  vi pod2.yaml
 1022  clear
 1023  ls
 1024  kubectl apply -f pod1.yaml -n=rajesh
 1025  kubectl apply -f pod2.yaml -n=rajesh
 1026  cleaer
 1027  clear
 1028  kubectl get pods -n=rajesh
 1029  kubectl get pods -n=rajesh --show-labesl
 1030  kubectl get pods -n=rajesh --show-labels
 1031  clear
 1032  kubectl get svc -n=rajesh
 1033  kubectl get svc
 1034  kubectl get svc -n=rajesh
 1035  kubectl create -h
 1036  clear
 1037  kubectl create service -h
 1038  kubectl create service clusterip -h
 1039  clear
 1040  kubectl create service clusterip my-cs --tcp=5678:80
 1041  kubectl get svc
 1042  kubectl delete svc my-cs
 1043  clear
 1044  kubectl create service clusterip my-cs --tcp=5678:80 -n=rajesh
 1045  kubectl get svc -h
 1046  clear
 1047  kubectl get svc -n=rajesh
 1048  kubectl get svc -n=rajesh --show-labels
 1049  kubectl get pods -n=rajesh --show-labels
 1050  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-cs -n=rajesh
 1051  cleae
 1052  clear
 1053  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-cs -n=rajesh
 1054  kubectl edit svc my-cs -n=rajesh
 1055  clear
 1056  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-cs -n=rajesh
 1057  curl http://10.99.110.185:5678
 1058  kubectl edit svc my-cs -n=rajesh
 1059  clear
 1060  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-cs -n=rajesh
 1061  curl http://10.99.110.185:5678
 1062  watch curl http://10.99.110.185:5678
 1063  vi pod2.yaml
 1064  kubectl apply -f pod2.yaml -n=rajesh
 1065  clear
 1066  watch curl http://10.99.110.185:5678
===================================

 1073  clear
 1074  kubectl create service nodeport -h
 1075  clear
 1076  kubectl create service nodeport my-ns --tcp=5678:80 -n=rajesh
 1077  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-ns -n=rajesh
 1078  kubectl edit svc my-ns -n=rajesh
 1079  clear
 1080  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-ns -n=rajesh
 1081  watch curl http://10.98.204.118:5678
 1082  clear
 1083  kubectl create service loadbalancer my-lb --tcp=5678:80 -n=rajesh
 1084  kubectl get pods -n=rajesh --show-labels;kubectl get svc -n=rajesh --show-labels;kubectl describe svc my-ns -n=rajesh
======================================

kubectl create deployment my-dep --image=scmgalaxy/nginx-devopsschoolv1 --replicas=5 -n=rajesh

kubectl expose deploy my-dep --port=80 --target-port=80 -n=rajesh

 1091  clear
 1092  kubectl expose -h
 1093  clear
 1094  kubectl create deployment my-dep --image=scmgalaxy/nginx-devopsschoolv1 --replicas=5 -n=rajesh
 1095  kubectl get svc -n=rajesh
 1096  kubectl expose deploy my-dep --port=80 --target-port=80 -n=rajesh
 1097  kubectl get svc -n=rajesh
 1098  kubectl describe svc my-dep -n=rajesh
 1099  clear
 1100  curl http://10.103.143.91
===========================================================================

Why We need Kubernetes Storage?
--------------------------------
We have PODs which is temporary.
---------------------------------
How to come Data of the POD - Persitent?
-------------------------------------
Kubernetes Volume
------------------------------
Types of Kubernetes Volume
------------------------------------
Technology 	Options			Volume Driver in kubernetes
-----------------------------------------
Block Storage
		Node Storage		hostpath
		EBS			
		Azure Disk			

File/Network Storage
		NFS			nfs
		EFS

Object Storage 
		S3
		Git


PersistentVolume types are implemented as plugins. Kubernetes currently supports the following plugins:

awsElasticBlockStore - AWS Elastic Block Store (EBS)
azureDisk - Azure Disk
azureFile - Azure File
cephfs - CephFS volume
csi - Container Storage Interface (CSI)
fc - Fibre Channel (FC) storage
flexVolume - FlexVolume
gcePersistentDisk - GCE Persistent Disk
glusterfs - Glusterfs volume
hostPath - HostPath volume (for single node testing only; WILL NOT WORK in a multi-node cluster; consider using local volume instead)
iscsi - iSCSI (SCSI over IP) storage
local - local storage devices mounted on nodes.
nfs - Network File System (NFS) storage
portworxVolume - Portworx volume
rbd - Rados Block Device (RBD) volume
vsphereVolume - vSphere VMDK volume
The following types of PersistentVolume are deprecated. This means that support is still available but will be removed in a future Kubernetes release.

cinder - Cinder (OpenStack block storage) (deprecated in v1.18)
flocker - Flocker storage (deprecated in v1.22)
quobyte - Quobyte volume (deprecated in v1.22)
storageos - StorageOS volume (deprecated in v1.22)
Older versions of Kubernetes also supported the following in-tree PersistentVolume types:

photonPersistentDisk - Photon controller persistent disk. (not available after v1.15)
scaleIO - ScaleIO volume (not available after v1.21)


========================================================
Admin of K8s AKA Admin of AWS
----------------
He would POOL of Storage
- Create pool of PV(S) (a volume which would be exist even pOD is gone)


User of K8s AKA Me as user of AWS
-------------------
He would use ONE of the pool of Storage
- PVC - Claim a 1 PV 
- Attached to POD
- Mount inside a container

https://www.devopsschool.com/blog/persistentvolume-persistentvolumeclaim-volumes-using-hostpath/



 1107  vi pv1.yaml
 1108  vi pv2.yaml
 1109  kubectl get pv
 1110  kubectl apply -f pv1.yaml
 1111  kubectl apply -f pv2.yaml
 1112  kubectl get pv
 1113  vi pvc1.yaml
 1114  kubectl get pvc -n=rajesh
 1115  kubectl apply -f pvc1.yaml -n=rajesh
 1116  kubectl get pvc -n=rajesh
 1117  kubectl get pv
 1118  vi pvc1.yaml
 1119  kubectl apply -f pvc1.yaml -n=rajesh
 1120  kubectl get pv
 1121  kubectl get pvc -n=rajesh
 1122  vi pod111.yaml
 1123  kubectl apply -f pod111.yaml -n=rajesh
 1124  kubectl get pods -n=rajesh
 1125  kubectl exec task-pv-pod touch /usr/share/nginx/html/index.html -n=rajesh
 1126  kubectl exec task-pv-pod ls /usr/share/nginx/html
 1127  kubectl exec task-pv-pod ls /usr/share/nginx/html -n=rajesh
 1128  clear
 1129  ls
 1130  kubectl delete -f pod111.yaml -n=rajesh
 1131  kubectl apply -f pod111.yaml -n=rajesh
 1132  kubectl exec task-pv-pod ls /usr/share/nginx/html -n=rajesh






https://www.devopsschool.com/blog/kubernetes-persistentvolume-and-persistentvolumeclaim-using-nfs-volume-types/


==============================================

https://www.devopsschool.com/blog/understanding-authentication-authorization-in-kubernetes/

=====================================

How We connect to API server?
---------------------------------
kubectl
	config
	$USER_HOME/.kube/config {Default}
	CURR_LOC/.kube/config
	export KUBECONFIG=/etc/kubernetes/admin.conf

config contains
- YAML

Clustor(S)
- Clustor1 = http://api-add:6443
- Clustor2 = http://api-add:6443
- Clustor3 = http://api-add:6443

User(s)
- Usr1 - key + cert
- Usr2 - key + cert
- Usr3 - key + cert

Context(S)
- Context1 = Clustor1 + Usr2 
- Context2 = Clustor2 + Usr1 
- Context3 = Clustor3 + Usr3 

curr-context: Clustor2

kubectl --context=Context1|2|3


 1136  more $HOME/.kube/config
 1137  clear
 1138  kubectl config
 1139  clear
 1140  kubectl config view
 1141  clear
 1142  ls
 1143  pwd
 1144  openssl genrsa -out employee.key 2048
 1145  ls
 1146  openssl req -new -key employee.key -out employee.csr -subj "/CN=employee/O=bitnami"
 1147  ls
 1148  openssl x509 -req -in employee.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out employee.crt -days 500
 1149  sudo openssl x509 -req -in employee.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out employee.crt -days 500
 1150  clear
 1151  ls
 1152  pwd
 1153  kubectl config set-credentials employee --client-certificate=/home/centos/rajesh/employee.crt  --client-key=/home/centos/rajesh/employee.key
 1154  kubectl config view
 1155  clear
 1156  kubectl config set-context employee-context --cluster=kubernetes --namespace=office --user=employee
 1157  kubectl config view
 1158  clear
 1159  kubectl create namespace office
 1160  kubectl --context=employee-context get pods
 1161  clear
 1162  ls
 1163  kubectl get roles
 1164  kubectl get roles -n=rajesh
 1165  kubectl get ns
 1166  clear
 1167  ls
 1168  vi role.yaml
 1169  kubectl apply -f role.yaml
 1170  vi role.yaml
 1171  kubectl apply -f role.yaml
 1172  kubectl get roles -n=office
 1173  vi rb.yaml
 1174  kubectl apply -f rb.yaml
 1175  kubectl get rolebinding -n=office
 1176  clear
 1177  kubectl --context=employee-context run nginx --image=nginx
 1178  kubectl --context=employee-context get svc
 1179  history
=======================================================
What is docker compose?
- Dev tools for creating - troublshooting - running container and images

tool named wit

docker-compose
		reads what?
		docker-compose.yaml
		contains
	
-------------
Service(s)

web
	build - dockerfile
	image - imagenmae
	port 
	vol
	net
	env

app
	build - dockerfile
	image - imagenmae
	port 
	vol
	net
	env

db 
	build - dockerfile
	image - imagenmae
	port 
	vol
	net
	env




------------------------------------------------------
docker-compose up 
		stop
		start
		logs
		ps
docker-compose down

https://www.devopsschool.com/blog/collection-example-of-docker-compose-program/


 403  clear
  404  ls
  405  cd
  406  ls
  407  sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
  408  sudo chmod +x /usr/local/bin/docker-compose
  409  sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
  410   docker-compose --version
  411  cd
  412  ls
  413  ls
  414  vi docker-compose.yaml
  415  docker-compose ps
  416* clea
  417  docker-compose -h
  418  clear
  419  ls
  420  docker-compose up -d
  421  clear
  422  docker-compose ps
  423  docker-compose logs
  424  clear
  425  docker-compose stop
  426  docker-compose ps
  427  docker-compose start
  428  docker-compose ps
  429  docker-compose down
  430  docker-compose ps
  431  history

























